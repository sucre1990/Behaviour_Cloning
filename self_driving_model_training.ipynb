{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "lines = []\n",
    "with open('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = next(reader, None)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "train_data, validation_data = train_test_split(lines, test_size = 0.2)\n",
    "def augmentation_flip(image, angle):\n",
    "    flipped_image = np.fliplr(image)\n",
    "    flipped_angle = -angle\n",
    "    return flipped_image, flipped_angle\n",
    "\n",
    "def preprocessing_images(image):\n",
    "    #corping the top and bottom image\n",
    "    new_image = image[50:140,:,:]\n",
    "    #converting to YUV color space as (nivida's paper's structure)\n",
    "    new_image = cv2.resize(new_image,(200, 66), interpolation = cv2.INTER_AREA)\n",
    "    new_image = cv2.cvtColor(new_image, cv2.COLOR_BGR2YUV) \n",
    "    #normalization\n",
    "\n",
    "    return new_image\n",
    "def image_generator(samples, flipped_aug = True, batch_size = 32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles=[]\n",
    "            for batch_sample in batch_samples:\n",
    "                name = 'data/IMG/' + batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                \n",
    "                # Converting image to YUV color space, resize to 66 * 200 and normalize\n",
    "                center_image = preprocessing_images(center_image)\n",
    "                \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                if flipped_aug == True:\n",
    "                    flipped_image, flipped_angle = augmentation_flip(center_image, center_angle)\n",
    "                    images.append(flipped_image)\n",
    "                    angles.append(flipped_angle)\n",
    "            X_image = np.array(images)\n",
    "            y_angle = np.array(angles)\n",
    "            yield shuffle(X_image, y_angle)\n",
    "\n",
    "train_generator = image_generator(train_data, batch_size = 32)\n",
    "validation_generator = image_generator( validation_data, batch_size = 32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  739.,   666.,   969.,  1537.,  1684.,   330.,  1192.,   662.,\n",
       "          556.,   842.]),\n",
       " array([-0.9663736 , -0.76973624, -0.57309888, -0.37646152, -0.17982416,\n",
       "         0.0168132 ,  0.21345056,  0.41008792,  0.60672528,  0.80336264,  1.        ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAEgSR1lAEhSR/1/fH34rJre8TgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f645168c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steering_angles = []\n",
    "for line in lines:\n",
    "    control = np.random.choice(10,1)\n",
    "    if control[0] < 1 or np.abs(float(line[3])) > 0.2:\n",
    "        steering_angles.append(float(line[3]))\n",
    "steering_angles = np.array(steering_angles)\n",
    "\n",
    "plt.hist(steering_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "42288/42288 [==============================] - 24s - loss: 0.1424 - val_loss: 0.0871\n",
      "Epoch 2/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0866 - val_loss: 0.0829\n",
      "Epoch 3/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0825 - val_loss: 0.0853\n",
      "Epoch 4/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0812 - val_loss: 0.0800\n",
      "Epoch 5/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0801 - val_loss: 0.0799\n",
      "Epoch 6/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0798 - val_loss: 0.0798\n",
      "Epoch 7/7\n",
      "42288/42288 [==============================] - 23s - loss: 0.0794 - val_loss: 0.0742\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255. - 0.5, input_shape = (66, 200, 3)))\n",
    "#The network structre is mimicing from Nvidia' paper\n",
    "#First with 3 5x5 convolutional layers\n",
    "    #First 5x5 convlutional layer 24 filters\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "    #Second 5x5 convlutional layer 36 filters\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "model.add(Activation('relu'))\n",
    "    #Third 5x5 convlutional layer 48 filters\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Then with 2 1-stride 3x3 convlolutional layers\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#At last with 3 fully connected layers\n",
    "    #Flatten the previous results\n",
    "model.add(Flatten())\n",
    "    #First fully connected layer\n",
    "model.add(Dense(100, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #Second fully connected layer\n",
    "model.add(Dense(50, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #Third fully connected layer\n",
    "model.add(Dense(10, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, W_regularizer=l2(0.001)))\n",
    "keras.optimizers.Adam(lr=0.01)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=\\\n",
    "                    len(train_data) * 2, validation_data=validation_generator,\\\n",
    "            nb_val_samples=len(validation_data), nb_epoch=7)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "50596/50596 [==============================] - 29s - loss: 0.1387 - val_loss: 0.0972\n",
      "Epoch 2/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0934 - val_loss: 0.0918\n",
      "Epoch 3/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0898 - val_loss: 0.0933\n",
      "Epoch 4/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0884 - val_loss: 0.0885\n",
      "Epoch 5/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0877 - val_loss: 0.0899\n",
      "Epoch 6/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0870 - val_loss: 0.0883\n",
      "Epoch 7/7\n",
      "50596/50596 [==============================] - 28s - loss: 0.0869 - val_loss: 0.0888\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255. - 0.5, input_shape = (66, 200, 3)))\n",
    "#The network structre is mimicing from Nvidia' paper\n",
    "#First with 3 5x5 convolutional layers\n",
    "    #First 5x5 convlutional layer 24 filters\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "    #Second 5x5 convlutional layer 36 filters\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "model.add(Activation('relu'))\n",
    "    #Third 5x5 convlutional layer 48 filters\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), W_regularizer=l2(0.005)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Then with 2 1-stride 3x3 convlolutional layers\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#At last with 3 fully connected layers\n",
    "    #Flatten the previous results\n",
    "model.add(Flatten())\n",
    "    #First fully connected layer\n",
    "model.add(Dense(100, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #Second fully connected layer\n",
    "model.add(Dense(50, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "    #Third fully connected layer\n",
    "model.add(Dense(10, W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, W_regularizer=l2(0.001)))\n",
    "keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=\\\n",
    "                    len(train_data) * 2, validation_data=validation_generator,\\\n",
    "            nb_val_samples=len(validation_data), nb_epoch=7)\n",
    "\n",
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50596/50596 [==============================] - 29s - loss: 0.0798 - val_loss: 0.0690\n",
      "Epoch 2/5\n",
      "50596/50596 [==============================] - 28s - loss: 0.0687 - val_loss: 0.0699\n",
      "Epoch 3/5\n",
      "50596/50596 [==============================] - 28s - loss: 0.0646 - val_loss: 0.0633\n",
      "Epoch 4/5\n",
      "50596/50596 [==============================] - 28s - loss: 0.0614 - val_loss: 0.0658\n",
      "Epoch 5/5\n",
      "50596/50596 [==============================] - 28s - loss: 0.0587 - val_loss: 0.0602\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Lambda, Dropout\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255. - 0.5, input_shape = (66, 200, 3)))\n",
    "#The network structre is mimicing from Nvidia' paper\n",
    "#First with 3 5x5 convolutional layers\n",
    "    #First 5x5 convlutional layer 24 filters\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "    #Second 5x5 convlutional layer 36 filters\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "    #Third 5x5 convlutional layer 48 filters\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Then with 2 1-stride 3x3 convlolutional layers\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "    #First3x3 convolutional layer\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "#At last with 3 fully connected layers\n",
    "    #Flatten the previous results\n",
    "model.add(Flatten())\n",
    "    #First fully connected layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "    #Second fully connected layer\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "    #Third fully connected layer\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1))\n",
    "keras.optimizers.Adam(lr=0.00001)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit_generator(train_generator, samples_per_epoch=\\\n",
    "                    len(train_data) * 2, validation_data=validation_generator,\\\n",
    "            nb_val_samples=len(validation_data), nb_epoch=5)\n",
    "\n",
    "model.save('model2.h5') \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    ", W_regularizer=l2(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import socketio\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "from PIL import Image\n",
    "from flask import Flask\n",
    "from io import BytesIO\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "model = None\n",
    "prev_image_array = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
